\chapteruaf{Using Cache Timings to Detect VMI}

\section{Motivation and Introduction}
In this chapter we discuss a statistical analysis of the time taken to write to a page after it has been forcibly ejected from cache. When we look at resources shared between a host and guest one of the obvious ones is the CPU cache.  When a VMI agent fetches memory from a guest VM it ends up in the CPU cache. The question is can this caching be measured by the guest VM?  We hypothesize that there will be a measurable decrease in the time taken to access a page at intervals where VMI has been performed on the VM. In order to make this more general we aim our experiment at the L3 cache specifically. While each core has its own L1 and L2 caches, the L3 cache is shared across all the cores on a CPU.  This will mean we will be able to tell if a VM has been monitored by VMI agent regardless of which core it's on. 


\section{Experiment}

We begin this experiment with the same physical setup described in chapter II.   Since this experiment will be specifically measuring the L3 cache timings we don't need to pin the hypervisor and VM to the same VCPU. This experiment is broken into two portions: the monitoring portion and the host portion. 

When a VMI agent is used on a VM the memory being analyzed is copied or mapped from the VM to the VMI agent. This will move this data into the CPU cache of the CPU  on which the VMI agent is being run. Suppose the VMI agent were co-located on the same CPU as the VM being monitored. This would mean that the VMI agent would be able to fetch the memory from cache rather than having to go out to main memory.This would cause a significant decrease in the time taken to fetch the data.  Now suppose that the process inside the target VM which is being monitored by the VMI agent flushes cache lines which its memory occupies. This should cause a measurable increase in the amount of time required to access the data which has been evicted. 

For this experiment a process (the monitoring process) will be run on the guest VM. This process begins by allocating a page of memory and seeding it using the mersenne twister algorithm~\cite{matsumoto_mersenne_1998}. The mersenne twister is chosen to increase the probability that page will be distinct from all other pages in memory. This is to ensure when the data is evicted from cache it will not be inadvertently loaded by other processes, which have the same data in memory. 


\begin{algorithm}\label{CacheProbe}
\end{algorithm}


The monitoring process will then take one time stamp using the chrono object described in section 4.2, write to a random element in the page, then take another time stamp, and record the difference between the timestamps. The monitoring process then flushes the cache using the X86 $clf$ instruction ~\cite{_intel_2014}. This instruction flushes a cacheline from all levels of cache on the CPU. Since instruction only flushes a cache line the page is simply iterated through until all cache lines are flushed. This process is then repeated 1,000,000 times. 

On the host side the VMI agent will fetch the memory from that process and page. The VMI agent was run at regular intervals during the experiment. Trials were performed where the VMI agent was run every 50$\mu s$ , 100 $\mu s$ , 200 $\mu s$, 1ms, 10ms, and 100ms. Trials were also performed where the target VM was not monitored by a VMI agent. 

\section{Analysis}

The result were plotted and it was expected that noticeable drops in the time taken to write to a page would be present at regular intervals where the VMI agent had mapped the guest data. From Fig Y we can see that these drops memory access time are not present. Why is this the case? According to Hennesy and Patterson ~\cite{hennessy_computer_2012} say that a cache miss has takes approximately 25ns. This is a full order of magnitude less than the overhead taken for our timing measurements. Can anything be salvaged from these results? 

When one takes a histogram of the results 3 one can see that the histograms are slightly different. To determine whether or not this difference is significant we employ the t-test ~\cite{welch_generalization_1947} on pairs of datasets. The t-test gives us a measure of the difference between two samples called the t-statistic. By integrating the student-t distribution from the t-statistic to the p-value can be determined. The p-value gives us the probability that the t-statistic could be obtained under the null hypothesis that both samples are drawn from the same population. 

For the initial set of tests the t-test is run between pairs of populations with the control population being unmonitored by VMI and the variable population being monitored by VMI at some regular interval. Table 1 shows the results. In all the tests performed the p-value was less than $10^{−6}$. A $p$-value this small indicates that we can reject the null hypothesis that both samples were drawn from the same population. As a result we can take conclude that VMI has been detected by this probe. In these tests 1,000,000 samples were used. This is an extremely large sample size and may not be useful for real time applications. The question now becomes can the sample size be reduced and still give acceptable results? Further how far can the sample be reduced and produce acceptable results? 


\begin{table}\label{TTestsCacheTiming}

  \begin{tabular}{| c | c | c | c | c | c |}
    \hline
    hypervisor & $50\mu s$ & $100\mu s$ & $200 \mu s$ & $1ms$ & $10ms$ \\ \hline
    Xen & -9.196 & -44.15 & -18.40 & -4.742 & -32.22 \\ \hline 
    Xen 100 Samples & -40.66 & -29.62 & -32.62 & -28.71 & -34.00 \\ \hline
    KVM & -12.25 & -12.33 & -11.29 & -12.25 & -11.36  \\ \hline
    KVM 100 Samples & -32.63 & -34.63 & -3.159 & -33.29 & -13.43  \\ \hline 
  \end{tabular}
  \caption{T Tests for Xen and KVM vs the null hypothesis that the no VMI has been used}
\end{table} 


\begin{table}\label{MannWhitneyCacheTiming}

  \begin{tabular}{| c | c | c | c | c | c |}
    \hline
    hypervisor & $50\mu s$ & $100\mu s$ & $200 \mu s$ & $1ms$ & $10ms$ \\ \hline
    Xen & -9.196 & -44.15 & -18.40 & -4.742 & -32.22 \\ \hline 
    Xen 100 Samples & -40.66 & -29.62 & -32.62 & -28.71 & -34.00 \\ \hline
    KVM & -12.25 & -12.33 & -11.29 & -12.25 & -11.36  \\ \hline
    KVM 100 Samples & -32.63 & -34.63 & -3.159 & -33.29 & -13.43  \\ \hline
  \end{tabular}
  \caption{T Tests for Xen and KVM vs the null hypothesis that the no VMI has been used}
\end{table}


\begin{center}\label{InfoGainsCacheAttack}
	\begin{table}
	  	\begin{tabular}{| c | c | c | c | c | c |}
		    \hline
		    hypervisor & $50\mu s$ & $100\mu s$ & $200 \mu s$ & $1ms$ & $10ms$ \\ \hline
		    Xen & 0.061 & 0.060 & 0.060 & 0.060 & 0.064 \\ \hline 
		    KVM & 0.070 & 0.069 & -0.071 & 0.070 & 0.073 \\ \hline   
		\end{tabular}
		\caption{Information Gain Results for Xen and KVM in bits}
  \end{table}
\end{center}


To determine this, we model the experiment as two random variables and considering the mutual information between them as discussed in chapter III. The results of the mutual information between the timing data and the presence or absence of VMI are shown in table 2, and demonstrate that by taking timing measurements, we gain as much as 0.08 bits of certainty about the VMI hypothesis. 


This indicates that the number of samples required can be reduced significantly from the original 1,000,000. We reduce the sample size to 100 samples which a 10,000 fold decrease in sample size. We perform the t-test again to determine if this reduction in sample size will still give positive results.  We can see from table <figure out table> that we are still able to determine the difference between the different samples. Again all p-values computed for these tests are less than $10^{−6}$. 


\section{Support Vector Machines}

\subsection{Theory}
After discovering that we need less than 100 samples in order to classify whether a sample has been monitored by a VMI agent we need a good machine learning classifier to test this on. For this classification we will use Support Vector Machines (SVM) introduced originally by Cortez and Vapnik ~\cite{cortes1995support} in 1995. SVMs begin by assuming data has the form 


\begin{equation}\label{SVM1}
	\{x_k,y_k\}\in \mathbb{R}^n \times \{-1,1\}
\end{equation}

where $x_k$ is some data point and $y_k$ is its classification (in our case monitored by VMI or not). We now wish to find a maximum margin hyperplane parameteried by $((\bm{w}),b)$. This hyperplane is selected such that it will seperate the classes $y_i=1$ and $y_i=-1$. Next we must choose a $((\bm{w}),b)$ such that we have the greatest distance between

\begin{equation}\label{SVM2}
	\bm{w}\cdot \bm{x} -b = 1
\end{equation}

and
\begin{equation}\label{SVM2-2}
	\bm{w}\cdot \bm{x} -b = -1 
\end{equation}

Now we make the assumption that the data is linearly seperable. While this may seem like this is severely limiting at first we can make this assumption using the ``kernel trick'' and map our features to some high-dimensional feature space. This will not be necessary in our case however given that our data is quite composed of a single feature repeated $100$ times. By assuming our data is linearly seperable we can select a $((\bm{w}),b)$ such that there are no points in between the planes denoted by ~\ref{SVM2} and ~\ref{SVM2-2}. 


\begin{figure}[p!]\label{MaxMargin}
	  \centering
	  \includegraphics[width=\textwidth]{figures/Svm_max_sep_hyperplane_with_margin.png}
	  \caption{A simple two dimensional example of an SVM}
\end{figure}

By examing figure (fig) we can see that we want to minimize the distance $\frac{2}{\|\bm{w}\|}$. In order to ensure that no points are in the margin we add the constraints
\begin{equation}\label{ConstraintOne}
	\bm{w}\cdot \bm{x_i} -b \ge 1 
\end{equation}

and 

\begin{equation}\label{ConstraintTwo}
	\bm{w}\cdot \bm{x_i} -b \le -1 
\end{equation}

for $y_i=1$ and $y_i=-1$ respectively. This can then be reduced to the form 

\begin{equation}\label{SVMFinal}
	y_k \times (\bm{w}\cdot \bm{x_i} - b) \ge 1 
\end{equation}

for $1 \le i \le n$. 

\subsection{Experiment}

Since we have determined that fewer than 100 samples is necessary to make a classification we begin by transforming our data into units of 100. Since we initially took 1,000,000 samples this is an easy transform, giving us a $10,000 \times 100$ data set. The first 100 sequential samples are transformed into one 100 dimensional data point, the next 100 are turned into the second data point and so forth. Each data point is labeled with a 1 for monitored by VMI and -1 for unmonitored by VMI. Since we know which samples were taken while being monitored by a VMI agent and which ones were not we can easily label our data. 

We then split the data into a training set and a testing set using 10 fold cross validation [cite]. 